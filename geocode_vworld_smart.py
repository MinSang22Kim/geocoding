import pandas as pd
import requests
import time
from typing import Optional, Tuple
import logging
from pathlib import Path
from datetime import datetime, timedelta
import re
import shutil

"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â­â­â­ ì„¤ì • ë³€ê²½ í•„ìš”ì‹œ ì•„ë˜ CONFIG ì„¹ì…˜ë§Œ ìˆ˜ì •í•˜ì„¸ìš”! â­â­â­
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

# ============================================================================
# âš™ï¸ CONFIG - ì—¬ê¸°ë§Œ ìˆ˜ì •í•˜ì„¸ìš”!
# ============================================================================

# ğŸ”‘ API í‚¤ ì„¤ì • (ê³„ì • ë°”ê¿€ ë•Œë§ˆë‹¤ ì—¬ê¸°ë§Œ ìˆ˜ì •!)
API_KEY = "CBDA8338-FEF2-34AE-9B04-D31B3597153F"  # â­ ì—¬ê¸° ìˆ˜ì •
# API_KEY = "01C14AE8-F90A-312A-92A2-395337FDB8AF"

# ğŸ“… ë‚ ì§œ ì„¤ì • (ìë™ vs ìˆ˜ë™)
USE_AUTO_DATE = False  # True: ì˜¤ëŠ˜ ë‚ ì§œ ìë™, False: ì•„ë˜ ë‚ ì§œ ì‚¬ìš©
MANUAL_DATE = "2025-10-30"  # USE_AUTO_DATEê°€ Falseì¼ ë•Œ ì‚¬ìš©

# ğŸ“Š í•˜ë£¨ í•œë„
DAILY_LIMIT = 80000  # API í•˜ë£¨ í•œë„

# ğŸ“‚ íŒŒì¼ ê²½ë¡œ
INPUT_FILE = "input/charger_v2.csv"
OUTPUT_DIR = "output"

# ============================================================================
# âš™ï¸ CONFIG ë - ì•„ë˜ëŠ” ìˆ˜ì • ê¸ˆì§€!
# ============================================================================

"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ì´ ì½”ë“œì˜ íŠ¹ì§•:
1. âœ… pendingë§Œ ì²˜ë¦¬ (success, failedëŠ” ê±´ë„ˆëœ€)
2. âœ… daily CSV íŒŒì¼ì„ ì•ˆì „í•˜ê²Œ ëˆ„ì  ì €ì¥ (ë®ì–´ì“°ê¸° ë°©ì§€)
3. âœ… API í‚¤ ë°”ë€Œë©´ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œì‘ ê°€ëŠ¥
4. âœ… 4ë§Œ ê±´ë§ˆë‹¤ ë³„ë„ íŒŒì¼ ìƒì„± ê°€ëŠ¥
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('geocoding.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

class VWorldGeocoder:
    def __init__(self, api_key: str, daily_limit: int = 40000):
        self.api_key = api_key
        self.base_url = "https://api.vworld.kr/req/address"
        self.daily_limit = daily_limit
        self.today_count = 0
        self.already_used_today = 0

    def clean_address(self, address: str) -> str:
        """ì£¼ì†Œ ì •ì œ"""
        if pd.isna(address) or not address.strip():
            return ""
        
        addr = address.strip()
        addr = re.sub(r'\([^)]*\)', '', addr)
        addr = re.sub(r'\[[^\]]*\]', '', addr)
        
        noise_keywords = [
            'ì™„ì†ì¶©ì „ê¸°', 'ê¸‰ì†ì¶©ì „ê¸°', 'ì¶©ì „ê¸°', 'ì¶©ì „ì†Œ', 
            'ì£¼ì°¨ì¥', 'ì§€í•˜ì£¼ì°¨ì¥', 'ì˜¥ì™¸ì£¼ì°¨ì¥',
            'ì…êµ¬', 'ì•', 'ì˜†', 'ë’¤', 'ë’¤í¸', 'ë§ì€í¸', 'ê±´ë„ˆí¸',
            'ìš°ì¸¡', 'ì¢Œì¸¡', 'ë°©ë©´', 'ë°©í–¥', 'ì¸ê·¼', 'ê·¼ì²˜',
            '1ì¸µ', '2ì¸µ', 'ì§€í•˜', 'B1', 'B2', 'ì¸µ'
        ]
        for keyword in noise_keywords:
            addr = addr.replace(keyword, ' ')
        
        addr = addr.replace('ê°•ì›íŠ¹ë³„ìì¹˜ë„', 'ê°•ì›ë„')
        addr = addr.replace('ì „ë¶íŠ¹ë³„ìì¹˜ë„', 'ì „ë¼ë¶ë„')
        addr = addr.replace('ì „ë‚¨íŠ¹ë³„ìì¹˜ë„', 'ì „ë¼ë‚¨ë„')
        addr = addr.replace('ì œì£¼íŠ¹ë³„ìì¹˜ë„', 'ì œì£¼ë„')
        
        corrections = {
            "í™ë•êµ¬": "í¥ë•êµ¬", "ì›ë¡±ë©´": "ì›”ë¡±ë©´", "ì›ì‚­ë¡œ": "ì›ë‹¹ë¡œ",
            "ì†¡ë°±ë¡œë¡œ": "ì†¡ë°±ë¡œ", "ë‹¬ì„±êµ° í˜„í’ë©´": "ë‹¬ì„±êµ° í˜„í’ì",
            "ì˜ˆì²œêµ° í˜¸ëª…ë©´": "ì˜ˆì²œêµ° í˜¸ëª…ì", "í˜„í’ë™ë¡œ": "í˜„í’ì¤‘ì•™ë¡œ",
            "í˜„í’ì„œë¡œ": "í˜„í’ì¤‘ì•™ë¡œ", "ë„ì²­ëŒ€ë¡œ": "ì¶©íš¨ë¡œ",
            "í–‰ë³µë¡œ": "ì¶©íš¨ë¡œ", "ì²­ì„ë¡œ": "ê²½ì¶©ëŒ€ë¡œ",
            "ìˆ˜íƒ€ì‚¬ë¡œ": "ìˆ˜íƒ€ì‚¬ê¸¸", "ë•í’ë¡œ": "ì‚¼ì²™ë¡œ",
        }
        for wrong, right in corrections.items():
            addr = addr.replace(wrong, right)

        addr = re.sub(r'([ê°€-í£])(\d)', r'\1 \2', addr)
        addr = re.sub(r'\s+', ' ', addr).strip()
        return addr

    def extract_address_candidates(self, address: str) -> list:
        """ë‹¤ì–‘í•œ ë ˆë²¨ì˜ ì£¼ì†Œ í›„ë³´ë¥¼ ìƒì„±"""
        candidates = [address]
        
        no_number = re.sub(r'\s+\d+(-\d+)?(\s|$)', ' ', address).strip()
        if no_number != address and len(no_number) > 5:
            candidates.append(no_number)
        
        road_match = re.match(r'(.+?[ì‹œë„êµ°êµ¬]\s+.+?[ìë©´ë™]?\s*.+?[ë¡œê¸¸ëŒ€ë¡œê°€])\s*', address)
        if road_match:
            road_only = road_match.group(1).strip()
            if road_only not in candidates and len(road_only) > 5:
                candidates.append(road_only)
        
        dong_match = re.match(r'(.+?[ì‹œë„êµ°êµ¬]\s+.+?[ìë©´ë™ë¦¬])', address)
        if dong_match:
            dong_only = dong_match.group(1).strip()
            if dong_only not in candidates and len(dong_only) > 5:
                candidates.append(dong_only)
        
        return candidates

    def geocode_address(self, address: str, jibun_address: str = None) -> Tuple[Optional[float], Optional[float], str]:
        """ì£¼ì†Œë¥¼ ì¢Œí‘œë¡œ ë³€í™˜"""
        if self.today_count >= self.daily_limit:
            return None, None, 'limit_reached'

        addresses_to_try = []
        
        if address and not pd.isna(address):
            cleaned = self.clean_address(address)
            if cleaned and len(cleaned) > 3:
                addresses_to_try.append((cleaned, 'road', 'ë„ë¡œëª…'))
        
        if jibun_address and not pd.isna(jibun_address):
            cleaned_jibun = self.clean_address(jibun_address)
            if cleaned_jibun and len(cleaned_jibun) > 3:
                addresses_to_try.append((cleaned_jibun, 'parcel', 'ì§€ë²ˆ'))

        if not addresses_to_try:
            return None, None, 'empty'

        for addr, addr_type, type_name in addresses_to_try:
            candidates = self.extract_address_candidates(addr)
            
            for i, candidate in enumerate(candidates):
                if len(candidate) < 3:
                    continue
                lat, lon, status = self._try_geocode(candidate, addr_type)
                if status == 'success':
                    level_names = ['ì •í™•ì£¼ì†Œ', 'ë„ë¡œëª…', 'ë„ë¡œê¸°ì¤€', 'ìë©´ë™']
                    level = level_names[i] if i < len(level_names) else 'ê´‘ì—­'
                    logging.info(f"âœ… ì„±ê³µ [{level}Â·{type_name}]: {candidate[:40]} â†’ ({lat:.6f}, {lon:.6f})")
                    return lat, lon, status
                time.sleep(0.08)

        return None, None, 'failed'

    def _try_geocode(self, address: str, addr_type: str = 'road') -> Tuple[Optional[float], Optional[float], str]:
        """VWorld API ìš”ì²­"""
        params = {
            'service': 'address', 'request': 'getcoord', 'version': '2.0',
            'crs': 'epsg:4326', 'address': address, 'refine': 'true',
            'simple': 'false', 'format': 'json', 'type': addr_type,
            'key': self.api_key
        }

        try:
            response = requests.get(self.base_url, params=params, timeout=10)
            self.today_count += 1

            if response.status_code == 200:
                data = response.json()
                res = data.get('response', {})
                status = res.get('status')
                result = res.get('result', {})

                if status == 'OK' and isinstance(result, dict) and 'point' in result:
                    lon = float(result['point']['x'])
                    lat = float(result['point']['y'])
                    return lat, lon, 'success'
            return None, None, 'failed'
        except:
            return None, None, 'failed'

def check_today_usage(df: pd.DataFrame, today_str: str) -> int:
    """ì˜¤ëŠ˜ ì´ë¯¸ ì²˜ë¦¬í•œ ê±´ìˆ˜ í™•ì¸"""
    if 'ì²˜ë¦¬ì¼ì‹œ' not in df.columns:
        return 0

    df['ì²˜ë¦¬ì¼ì‹œ'] = df['ì²˜ë¦¬ì¼ì‹œ'].fillna("").astype(str)

    if pd.api.types.is_datetime64_any_dtype(df['ì²˜ë¦¬ì¼ì‹œ']):
        mask = df['ì²˜ë¦¬ì¼ì‹œ'].dt.strftime("%Y-%m-%d").eq(today_str)
    else:
        mask = df['ì²˜ë¦¬ì¼ì‹œ'].str.startswith(today_str)

    today_processed = df[mask]
    return len(today_processed)

def analyze_situation(df: pd.DataFrame, today_str: str):
    """í˜„ì¬ ìƒí™© ë¶„ì„ ë° ì•ˆë‚´"""
    total = len(df)
    success = (df['ì²˜ë¦¬ìƒíƒœ'] == 'success').sum()
    failed = (df['ì²˜ë¦¬ìƒíƒœ'] == 'failed').sum()
    pending = (df['ì²˜ë¦¬ìƒíƒœ'] == 'pending').sum()
    today_processed = check_today_usage(df, today_str)
    
    logging.info("=" * 70)
    logging.info("ğŸ“Š í˜„ì¬ ìƒí™© ë¶„ì„")
    logging.info("=" * 70)
    logging.info(f"ì „ì²´:          {total:>10,}ê±´")
    logging.info(f"âœ… ì™„ë£Œ:       {success:>10,}ê±´ ({success/total*100:>5.1f}%)")
    logging.info(f"âŒ ì‹¤íŒ¨:       {failed:>10,}ê±´ ({failed/total*100:>5.1f}%)")
    logging.info(f"â³ ëŒ€ê¸°:       {pending:>10,}ê±´ ({pending/total*100:>5.1f}%)")
    logging.info(f"ğŸ“… ì˜¤ëŠ˜ ì²˜ë¦¬:  {today_processed:>10,}ê±´")
    logging.info("=" * 70)
    
    # ìƒí™© íŒë‹¨
    if today_processed >= 39000:
        logging.warning("\nâš ï¸  ì˜¤ëŠ˜ì€ ì´ë¯¸ ê±°ì˜ í•œë„(40,000ê±´)ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤!")
        logging.warning(f"   ì˜¤ëŠ˜ ì²˜ë¦¬: {today_processed:,}ê±´")
        logging.warning(f"   ë‚¨ì€ í•œë„: {40000 - today_processed:,}ê±´")
        logging.info("\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
        logging.info("   â†’ ë‚´ì¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”")
        logging.info("   â†’ ì˜¤ëŠ˜ ë” ì‹¤í–‰í•˜ë ¤ë©´ ê·¸ëŒ€ë¡œ ì§„í–‰í•˜ë©´ ë©ë‹ˆë‹¤")
        
        proceed = input("\nê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
        if proceed != 'y':
            logging.info("âŒ ì¢…ë£Œí•©ë‹ˆë‹¤. ë‚´ì¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”!")
            return False
    
    elif today_processed > 0:
        logging.info(f"\nğŸ’¡ ì˜¤ëŠ˜ ì´ë¯¸ {today_processed:,}ê±´ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.")
        logging.info(f"   ë‚¨ì€ í•œë„: {40000 - today_processed:,}ê±´")
        logging.info("   â†’ ì´ì–´ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤")
    
    else:
        logging.info("\nğŸ’¡ ì˜¤ëŠ˜ ì²˜ìŒ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        logging.info(f"   í•œë„: 40,000ê±´")
    
    if pending == 0:
        logging.info("\nğŸ‰ ëª¨ë“  ëŒ€ê¸° ì¤‘ì¸ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ!")
        if failed > 0:
            logging.info(f"ğŸ’¡ ì‹¤íŒ¨í•œ {failed:,}ê±´ì€ ë‹¤ì‹œ ì‹œë„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return False
    
    return True


def load_progress(progress_file: Path) -> Optional[pd.DataFrame]:
    """ì§„í–‰ íŒŒì¼ ë¡œë“œ"""
    if progress_file.exists():
        try:
            logging.info(f"ğŸ“‚ ì§„í–‰ íŒŒì¼ ë¡œë“œ: {progress_file}")
            return pd.read_csv(progress_file, encoding='utf-8-sig', low_memory=False)
        except Exception as e:
            logging.warning(f"âš ï¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
    return None


def save_progress_safe(df: pd.DataFrame, progress_file: Path):
    """ì•ˆì „í•œ ì €ì¥"""
    try:
        temp_file = Path(str(progress_file) + '.tmp')
        df.to_csv(temp_file, index=False, encoding='utf-8-sig')
        
        if progress_file.exists():
            backup_file = Path(str(progress_file) + '.backup')
            shutil.copy2(progress_file, backup_file)
        
        shutil.move(str(temp_file), str(progress_file))
        logging.info(f"ğŸ’¾ progress.csv ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        logging.error(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
        raise


def save_daily_backup_safe(df: pd.DataFrame, output_dir: Path, today_str: str):
    """
    ì˜¤ëŠ˜ ì²˜ë¦¬í•œ ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê²Œ ëˆ„ì  ì €ì¥
    - ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ì´ì–´ë¶™ì„ (ë®ì–´ì“°ê¸° ë°©ì§€)
    - ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰í•´ë„ ì•ˆì „
    """
    try:
        # ì˜¤ëŠ˜ ì²˜ë¦¬í•œ ë°ì´í„° í•„í„°ë§
        df['ì²˜ë¦¬ì¼ì‹œ'] = df['ì²˜ë¦¬ì¼ì‹œ'].fillna("").astype(str)
        
        today_processed = df[
            df['ì²˜ë¦¬ì¼ì‹œ'].str.startswith(today_str)
        ].copy()
        
        if len(today_processed) == 0:
            logging.warning(f"âš ï¸ ì˜¤ëŠ˜({today_str}) ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # íŒŒì¼ëª… ìƒì„±
        today_file = today_str.replace('-', '')
        daily_file = output_dir / f"daily_{today_file}.csv"
        
        # ê¸°ì¡´ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
        if daily_file.exists():
            logging.info(f"ğŸ“‚ ê¸°ì¡´ daily íŒŒì¼ ë°œê²¬: {daily_file.name}")
            
            # ê¸°ì¡´ íŒŒì¼ ì½ê¸°
            existing_df = pd.read_csv(daily_file, encoding='utf-8-sig', low_memory=False)
            existing_count = len(existing_df)
            
            # ìƒˆë¡œìš´ ë°ì´í„°ì™€ ë³‘í•© (ì¤‘ë³µ ì œê±°)
            # ì¸ë±ìŠ¤ ê¸°ì¤€ìœ¼ë¡œ ìµœì‹  ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸
            combined = existing_df.set_index(existing_df.index)
            for idx in today_processed.index:
                if idx < len(combined):
                    combined.iloc[idx] = today_processed.loc[idx]
                else:
                    # ìƒˆë¡œìš´ ì¸ë±ìŠ¤ë©´ ì¶”ê°€
                    combined = pd.concat([combined, today_processed.loc[[idx]]])
            
            combined.reset_index(drop=True, inplace=True)
            
            # ì €ì¥
            combined.to_csv(daily_file, index=False, encoding='utf-8-sig')
            
            new_count = len(combined)
            added_count = new_count - existing_count
            
            logging.info("=" * 70)
            logging.info(f"ğŸ“… ì¼ì¼ ë°±ì—… ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
            logging.info(f"   íŒŒì¼: {daily_file.name}")
            logging.info(f"   ê¸°ì¡´: {existing_count:,}ê±´ â†’ í˜„ì¬: {new_count:,}ê±´ (+{added_count:,}ê±´)")
            
            success_count = (combined['ì²˜ë¦¬ìƒíƒœ'] == 'success').sum()
            failed_count = (combined['ì²˜ë¦¬ìƒíƒœ'] == 'failed').sum()
            logging.info(f"   ì„±ê³µ: {success_count:,}ê±´, ì‹¤íŒ¨: {failed_count:,}ê±´")
            logging.info("=" * 70)
            
        else:
            # ìƒˆ íŒŒì¼ ìƒì„±
            today_processed.to_csv(daily_file, index=False, encoding='utf-8-sig')
            
            success_count = (today_processed['ì²˜ë¦¬ìƒíƒœ'] == 'success').sum()
            failed_count = (today_processed['ì²˜ë¦¬ìƒíƒœ'] == 'failed').sum()
            
            logging.info("=" * 70)
            logging.info(f"ğŸ“… ì¼ì¼ ë°±ì—… ìƒì„± ì™„ë£Œ!")
            logging.info(f"   íŒŒì¼: {daily_file.name}")
            logging.info(f"   ì´ {len(today_processed):,}ê±´ (ì„±ê³µ: {success_count:,}, ì‹¤íŒ¨: {failed_count:,})")
            logging.info("=" * 70)
        
    except Exception as e:
        logging.error(f"âŒ ì¼ì¼ ë°±ì—… ì‹¤íŒ¨: {e}")
        import traceback
        logging.error(traceback.format_exc())


def main():
    # CONFIGì—ì„œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    output_dir = Path(OUTPUT_DIR)
    progress_file = output_dir / "progress.csv"
    
    output_dir.mkdir(exist_ok=True)
    
    # ë‚ ì§œ ì„¤ì •
    if USE_AUTO_DATE:
        today_str = datetime.now().strftime('%Y-%m-%d')
        logging.info(f"ğŸ•’ today_str ê³„ì‚°ê°’: {today_str}")
    else:
        today_str = MANUAL_DATE
    
    logging.info("=" * 70)
    logging.info(f"ğŸš€ ì§€ì˜¤ì½”ë”© ìë™ ì‹¤í–‰")
    logging.info(f"   ğŸ“… í˜„ì¬ ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logging.info(f"   ğŸ—“ï¸  ì²˜ë¦¬ ë‚ ì§œ: {today_str}")
    logging.info(f"   ğŸ”‘ API í‚¤: {API_KEY[:10]}...{API_KEY[-10:]}")
    logging.info("=" * 70)

    # ì§„í–‰ íŒŒì¼ ë¡œë“œ ë˜ëŠ” ìƒˆë¡œ ìƒì„±
    progress_df = load_progress(progress_file)
    if progress_df is not None:
        df = progress_df
    else:
        logging.info(f"ğŸ“‚ ì›ë³¸ íŒŒì¼ ì½ê¸°: {INPUT_FILE}")
        df = pd.read_csv(INPUT_FILE, encoding='utf-8-sig')
        df['ìœ„ë„'] = None
        df['ê²½ë„'] = None
        df['ì²˜ë¦¬ìƒíƒœ'] = 'pending'
        df['ì²˜ë¦¬ì¼ì‹œ'] = None
        logging.info(f"âœ… {len(df):,}ê±´ ë¡œë“œ (ì‹ ê·œ)")

    # ìƒí™© ë¶„ì„ ë° ì‹¤í–‰ ì—¬ë¶€ ê²°ì •
    if not analyze_situation(df, today_str):
        return

    # ì˜¤ëŠ˜ ì´ë¯¸ ì‚¬ìš©í•œ í•œë„ ê³„ì‚°
    already_used = check_today_usage(df, today_str)
    remaining_limit = DAILY_LIMIT - already_used

    logging.info(f"\nâš¡ ì‹¤í–‰ ì‹œì‘ (ë‚¨ì€ í•œë„: {remaining_limit:,}ê±´)")
    logging.info("=" * 70 + "\n")

    geocoder = VWorldGeocoder(API_KEY, remaining_limit)
    geocoder.already_used_today = already_used

    success_count = 0
    fail_count = 0
    skip_count = 0
    start_time = time.time()

    # â­â­â­ í•µì‹¬: pending ìƒíƒœë§Œ ì²˜ë¦¬ (successì™€ failedëŠ” ê±´ë„ˆëœ€) â­â­â­
    pending_indices = df[df['ì²˜ë¦¬ìƒíƒœ'] == 'pending'].index
    total_success = (df['ì²˜ë¦¬ìƒíƒœ'] == 'success').sum()
    total_failed = (df['ì²˜ë¦¬ìƒíƒœ'] == 'failed').sum()
    
    logging.info(f"ğŸ“ ì²˜ë¦¬ ëŒ€ìƒ: {len(pending_indices):,}ê±´ (pendingë§Œ)")
    logging.info(f"ğŸ”„ ê±´ë„ˆëœ€: {total_success + total_failed:,}ê±´ (ì™„ë£Œ {total_success:,} + ì‹¤íŒ¨ {total_failed:,})\n")

    try:
        for idx in pending_indices:
            # í•œë„ ì²´í¬
            if geocoder.today_count >= remaining_limit:
                logging.warning("=" * 70)
                logging.warning(f"âš ï¸  ì˜¤ëŠ˜ í•œë„ ë„ë‹¬!")
                logging.warning(f"   ì˜¤ëŠ˜ ì´ ì²˜ë¦¬: {already_used + geocoder.today_count:,}ê±´")
                logging.warning("=" * 70)
                break

            road_address = df.at[idx, 'ì£¼ì†Œ'] if 'ì£¼ì†Œ' in df.columns else None
            jibun_address = df.at[idx, 'ì§€ë²ˆ ì£¼ì†Œ'] if 'ì§€ë²ˆ ì£¼ì†Œ' in df.columns else None

            lat, lon, status = geocoder.geocode_address(road_address, jibun_address)

            df.at[idx, 'ìœ„ë„'] = lat
            df.at[idx, 'ê²½ë„'] = lon
            df.at[idx, 'ì²˜ë¦¬ìƒíƒœ'] = status
            df.at[idx, 'ì²˜ë¦¬ì¼ì‹œ'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

            if status == 'success':
                success_count += 1
            elif status == 'failed':
                fail_count += 1

            if geocoder.today_count % 50 == 0:
                rate = (success_count / geocoder.today_count * 100) if geocoder.today_count > 0 else 0
                elapsed = time.time() - start_time
                speed = geocoder.today_count / elapsed if elapsed > 0 else 0
                remaining = remaining_limit - geocoder.today_count
                eta_min = int((remaining / speed / 60)) if speed > 0 else 0
                
                logging.info(f"ğŸ“Š {already_used + geocoder.today_count:>5,}ê±´ (ì˜¤ëŠ˜) | "
                             f"ì„±ê³µ: {success_count:>4,} ({rate:>4.1f}%) | "
                             f"{speed:>4.1f}ê±´/ì´ˆ | "
                             f"ë‚¨ì€ì‹œê°„: {eta_min}ë¶„")

            if geocoder.today_count % 1000 == 0:
                save_progress_safe(df, progress_file)

            time.sleep(0.12)

        # â­ ìµœì¢… ì €ì¥
        save_progress_safe(df, progress_file)
        
        # â­â­â­ ë°˜ë“œì‹œ daily ë°±ì—… ì €ì¥ (ì•ˆì „í•œ ëˆ„ì  ë°©ì‹) â­â­â­
        if geocoder.today_count > 0:
            logging.info("\nğŸ’¾ ì¼ì¼ ë°±ì—… íŒŒì¼ ì €ì¥ ì¤‘...")
            save_daily_backup_safe(df, output_dir, today_str)
        else:
            logging.warning("\nâš ï¸ ì˜¤ëŠ˜ ì²˜ë¦¬í•œ ë°ì´í„°ê°€ ì—†ì–´ daily íŒŒì¼ì„ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    except KeyboardInterrupt:
        logging.warning("\nâš ï¸  ì¤‘ë‹¨ë¨. ì €ì¥ ì¤‘...")
        save_progress_safe(df, progress_file)
        if geocoder.today_count > 0:
            save_daily_backup_safe(df, output_dir, today_str)
        return

    # ìµœì¢… í†µê³„
    elapsed_time = time.time() - start_time
    total_today = already_used + geocoder.today_count

    logging.info("\n" + "=" * 70)
    logging.info("ğŸ¯ ì˜¤ëŠ˜ ì‘ì—… ì™„ë£Œ")
    logging.info("=" * 70)
    logging.info(f"ì˜¤ëŠ˜ ì´ ì²˜ë¦¬:  {total_today:>10,}ê±´")
    logging.info(f"ì´ë²ˆ ì‹¤í–‰:     {geocoder.today_count:>10,}ê±´")
    logging.info(f"  âœ… ì„±ê³µ:     {success_count:>10,}ê±´")
    logging.info(f"  âŒ ì‹¤íŒ¨:     {fail_count:>10,}ê±´")
    logging.info(f"â±ï¸  ì†Œìš”ì‹œê°„:   {int(elapsed_time//60)}ë¶„ {int(elapsed_time%60)}ì´ˆ")
    
    total = len(df)
    total_success = (df['ì²˜ë¦¬ìƒíƒœ'] == 'success').sum()
    total_failed = (df['ì²˜ë¦¬ìƒíƒœ'] == 'failed').sum()
    total_pending = (df['ì²˜ë¦¬ìƒíƒœ'] == 'pending').sum()
    
    logging.info("-" * 70)
    logging.info(f"ì „ì²´ ì§„í–‰ë¥ :   {total_success/total*100:>5.1f}% ({total_success:,}/{total:,}ê±´)")
    logging.info(f"ì‹¤íŒ¨:          {total_failed:>10,}ê±´ (ì¬ì‹œë„ ì•ˆ í•¨)")
    logging.info(f"ë‚¨ì€ ì‘ì—…:     {total_pending:>10,}ê±´")
    
    if total_pending > 0:
        est_days = (total_pending + 39999) // 40000
        logging.info(f"ì˜ˆìƒ ì†Œìš”:     ì•½ {est_days}ì¼")
        logging.info("\nğŸ’¡ ê°™ì€ ëª…ë ¹ì–´ë¡œ ì´ì–´ì„œ ì§„í–‰í•˜ì„¸ìš”!")
        logging.info("   â†’ py geocode_vworld_smart_v2.py")
    else:
        logging.info("\nğŸ‰ ì „ì²´ ì™„ë£Œ!")
    
    logging.info("=" * 70)

if __name__ == "__main__":
    main()
    