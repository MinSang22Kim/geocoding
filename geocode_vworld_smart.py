import pandas as pd
import requests
import time
from typing import Optional, Tuple
import logging
from pathlib import Path
from datetime import datetime, timedelta
import re
import shutil

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('geocoding.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

class VWorldGeocoder:
    def __init__(self, api_key: str, daily_limit: int = 40000):
        self.api_key = api_key
        self.base_url = "https://api.vworld.kr/req/address"
        self.daily_limit = daily_limit
        self.today_count = 0
        self.already_used_today = 0

    def clean_address(self, address: str) -> str:
        """ì£¼ì†Œ ì •ì œ"""
        if pd.isna(address) or not address.strip():
            return ""
        
        addr = address.strip()
        addr = re.sub(r'\([^)]*\)', '', addr)
        addr = re.sub(r'\[[^\]]*\]', '', addr)
        
        noise_keywords = [
            'ì™„ì†ì¶©ì „ê¸°', 'ê¸‰ì†ì¶©ì „ê¸°', 'ì¶©ì „ê¸°', 'ì¶©ì „ì†Œ', 
            'ì£¼ì°¨ì¥', 'ì§€í•˜ì£¼ì°¨ì¥', 'ì˜¥ì™¸ì£¼ì°¨ì¥',
            'ì…êµ¬', 'ì•', 'ì˜†', 'ë’¤', 'ë’¤í¸', 'ë§ì€í¸', 'ê±´ë„ˆí¸',
            'ìš°ì¸¡', 'ì¢Œì¸¡', 'ë°©ë©´', 'ë°©í–¥', 'ì¸ê·¼', 'ê·¼ì²˜',
            '1ì¸µ', '2ì¸µ', 'ì§€í•˜', 'B1', 'B2', 'ì¸µ'
        ]
        for keyword in noise_keywords:
            addr = addr.replace(keyword, ' ')
        
        addr = addr.replace('ê°•ì›íŠ¹ë³„ìì¹˜ë„', 'ê°•ì›ë„')
        addr = addr.replace('ì „ë¶íŠ¹ë³„ìì¹˜ë„', 'ì „ë¼ë¶ë„')
        addr = addr.replace('ì „ë‚¨íŠ¹ë³„ìì¹˜ë„', 'ì „ë¼ë‚¨ë„')
        addr = addr.replace('ì œì£¼íŠ¹ë³„ìì¹˜ë„', 'ì œì£¼ë„')
        
        corrections = {
            "í™ë•êµ¬": "í¥ë•êµ¬", "ì›ë¡±ë©´": "ì›”ë¡±ë©´", "ì›ì‚­ë¡œ": "ì›ë‹¹ë¡œ",
            "ì†¡ë°±ë¡œë¡œ": "ì†¡ë°±ë¡œ", "ë‹¬ì„±êµ° í˜„í’ë©´": "ë‹¬ì„±êµ° í˜„í’ì",
            "ì˜ˆì²œêµ° í˜¸ëª…ë©´": "ì˜ˆì²œêµ° í˜¸ëª…ì", "í˜„í’ë™ë¡œ": "í˜„í’ì¤‘ì•™ë¡œ",
            "í˜„í’ì„œë¡œ": "í˜„í’ì¤‘ì•™ë¡œ", "ë„ì²­ëŒ€ë¡œ": "ì¶©íš¨ë¡œ",
            "í–‰ë³µë¡œ": "ì¶©íš¨ë¡œ", "ì²­ì„ë¡œ": "ê²½ì¶©ëŒ€ë¡œ",
            "ìˆ˜íƒ€ì‚¬ë¡œ": "ìˆ˜íƒ€ì‚¬ê¸¸", "ë•í’ë¡œ": "ì‚¼ì²™ë¡œ",
        }
        for wrong, right in corrections.items():
            addr = addr.replace(wrong, right)

        addr = re.sub(r'([ê°€-í£])(\d)', r'\1 \2', addr)
        addr = re.sub(r'\s+', ' ', addr).strip()
        return addr

    def extract_address_candidates(self, address: str) -> list:
        """ë‹¤ì–‘í•œ ë ˆë²¨ì˜ ì£¼ì†Œ í›„ë³´ë¥¼ ìƒì„±"""
        candidates = [address]
        
        no_number = re.sub(r'\s+\d+(-\d+)?(\s|$)', ' ', address).strip()
        if no_number != address and len(no_number) > 5:
            candidates.append(no_number)
        
        road_match = re.match(r'(.+?[ì‹œë„êµ°êµ¬]\s+.+?[ìë©´ë™]?\s*.+?[ë¡œê¸¸ëŒ€ë¡œê°€])\s*', address)
        if road_match:
            road_only = road_match.group(1).strip()
            if road_only not in candidates and len(road_only) > 5:
                candidates.append(road_only)
        
        dong_match = re.match(r'(.+?[ì‹œë„êµ°êµ¬]\s+.+?[ìë©´ë™ë¦¬])', address)
        if dong_match:
            dong_only = dong_match.group(1).strip()
            if dong_only not in candidates and len(dong_only) > 5:
                candidates.append(dong_only)
        
        return candidates

    def geocode_address(self, address: str, jibun_address: str = None) -> Tuple[Optional[float], Optional[float], str]:
        """ì£¼ì†Œë¥¼ ì¢Œí‘œë¡œ ë³€í™˜"""
        if self.today_count >= self.daily_limit:
            return None, None, 'limit_reached'

        addresses_to_try = []
        
        if address and not pd.isna(address):
            cleaned = self.clean_address(address)
            if cleaned and len(cleaned) > 3:
                addresses_to_try.append((cleaned, 'road', 'ë„ë¡œëª…'))
        
        if jibun_address and not pd.isna(jibun_address):
            cleaned_jibun = self.clean_address(jibun_address)
            if cleaned_jibun and len(cleaned_jibun) > 3:
                addresses_to_try.append((cleaned_jibun, 'parcel', 'ì§€ë²ˆ'))

        if not addresses_to_try:
            return None, None, 'empty'

        for addr, addr_type, type_name in addresses_to_try:
            candidates = self.extract_address_candidates(addr)
            
            for i, candidate in enumerate(candidates):
                if len(candidate) < 3:
                    continue
                lat, lon, status = self._try_geocode(candidate, addr_type)
                if status == 'success':
                    level_names = ['ì •í™•ì£¼ì†Œ', 'ë„ë¡œëª…', 'ë„ë¡œê¸°ì¤€', 'ìë©´ë™']
                    level = level_names[i] if i < len(level_names) else 'ê´‘ì—­'
                    logging.info(f"âœ… ì„±ê³µ [{level}Â·{type_name}]: {candidate[:40]} â†’ ({lat:.6f}, {lon:.6f})")
                    return lat, lon, status
                time.sleep(0.08)

        return None, None, 'failed'

    def _try_geocode(self, address: str, addr_type: str = 'road') -> Tuple[Optional[float], Optional[float], str]:
        """VWorld API ìš”ì²­"""
        params = {
            'service': 'address', 'request': 'getcoord', 'version': '2.0',
            'crs': 'epsg:4326', 'address': address, 'refine': 'true',
            'simple': 'false', 'format': 'json', 'type': addr_type,
            'key': self.api_key
        }

        try:
            response = requests.get(self.base_url, params=params, timeout=10)
            self.today_count += 1

            if response.status_code == 200:
                data = response.json()
                res = data.get('response', {})
                status = res.get('status')
                result = res.get('result', {})

                if status == 'OK' and isinstance(result, dict) and 'point' in result:
                    lon = float(result['point']['x'])
                    lat = float(result['point']['y'])
                    return lat, lon, 'success'
            return None, None, 'failed'
        except:
            return None, None, 'failed'

def check_today_usage(df: pd.DataFrame, today_str: str) -> int:
    """ì˜¤ëŠ˜ ì´ë¯¸ ì²˜ë¦¬í•œ ê±´ìˆ˜ í™•ì¸"""
    if 'ì²˜ë¦¬ì¼ì‹œ' not in df.columns:
        return 0

    # NaN â†’ ë¹ˆ ë¬¸ìì—´, ê·¸ë¦¬ê³  ëª¨ë“  ê°’ ë¬¸ìì—´ë¡œ ë³€í™˜
    df['ì²˜ë¦¬ì¼ì‹œ'] = df['ì²˜ë¦¬ì¼ì‹œ'].fillna("").astype(str)

    # í˜¹ì‹œ 'ì²˜ë¦¬ì¼ì‹œ'ê°€ datetime íƒ€ì…ìœ¼ë¡œ ì €ì¥ë˜ì–´ ìˆëŠ” ê²½ìš° ëŒ€ë¹„
    if pd.api.types.is_datetime64_any_dtype(df['ì²˜ë¦¬ì¼ì‹œ']):
        mask = df['ì²˜ë¦¬ì¼ì‹œ'].dt.strftime("%Y-%m-%d").eq(today_str)
    else:
        mask = df['ì²˜ë¦¬ì¼ì‹œ'].str.startswith(today_str)

    today_processed = df[mask]
    return len(today_processed)

def analyze_situation(df: pd.DataFrame, today_str: str):
    """í˜„ì¬ ìƒí™© ë¶„ì„ ë° ì•ˆë‚´"""
    total = len(df)
    success = (df['ì²˜ë¦¬ìƒíƒœ'] == 'success').sum()
    pending = (df['ì²˜ë¦¬ìƒíƒœ'] == 'pending').sum()
    today_processed = check_today_usage(df, today_str)
    
    logging.info("=" * 70)
    logging.info("ğŸ“Š í˜„ì¬ ìƒí™© ë¶„ì„")
    logging.info("=" * 70)
    logging.info(f"ì „ì²´:          {total:>10,}ê±´")
    logging.info(f"âœ… ì™„ë£Œ:       {success:>10,}ê±´ ({success/total*100:>5.1f}%)")
    logging.info(f"â³ ëŒ€ê¸°:       {pending:>10,}ê±´ ({pending/total*100:>5.1f}%)")
    logging.info(f"ğŸ“… ì˜¤ëŠ˜ ì²˜ë¦¬:  {today_processed:>10,}ê±´")
    logging.info("=" * 70)
    
    # ìƒí™© íŒë‹¨
    if today_processed >= 39000:
        logging.warning("\nâš ï¸  ì˜¤ëŠ˜ì€ ì´ë¯¸ ê±°ì˜ í•œë„(40,000ê±´)ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤!")
        logging.warning(f"   ì˜¤ëŠ˜ ì²˜ë¦¬: {today_processed:,}ê±´")
        logging.warning(f"   ë‚¨ì€ í•œë„: {40000 - today_processed:,}ê±´")
        logging.info("\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
        logging.info("   â†’ ë‚´ì¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”")
        logging.info("   â†’ ì˜¤ëŠ˜ ë” ì‹¤í–‰í•˜ë ¤ë©´ ê·¸ëŒ€ë¡œ ì§„í–‰í•˜ë©´ ë©ë‹ˆë‹¤")
        
        proceed = input("\nê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
        if proceed != 'y':
            logging.info("âŒ ì¢…ë£Œí•©ë‹ˆë‹¤. ë‚´ì¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”!")
            return False
    
    elif today_processed > 0:
        logging.info(f"\nğŸ’¡ ì˜¤ëŠ˜ ì´ë¯¸ {today_processed:,}ê±´ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.")
        logging.info(f"   ë‚¨ì€ í•œë„: {40000 - today_processed:,}ê±´")
        logging.info("   â†’ ì´ì–´ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤")
    
    else:
        logging.info("\nğŸ’¡ ì˜¤ëŠ˜ ì²˜ìŒ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        logging.info(f"   í•œë„: 40,000ê±´")
    
    if pending == 0:
        logging.info("\nğŸ‰ ëª¨ë“  ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ!")
        return False
    
    return True


def load_progress(progress_file: Path) -> Optional[pd.DataFrame]:
    """ì§„í–‰ íŒŒì¼ ë¡œë“œ"""
    if progress_file.exists():
        try:
            logging.info(f"ğŸ“‚ ì§„í–‰ íŒŒì¼ ë¡œë“œ: {progress_file}")
            return pd.read_csv(progress_file, encoding='utf-8-sig', low_memory=False)
        except Exception as e:
            logging.warning(f"âš ï¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
    return None


def save_progress_safe(df: pd.DataFrame, progress_file: Path):
    """ì•ˆì „í•œ ì €ì¥"""
    try:
        temp_file = Path(str(progress_file) + '.tmp')
        df.to_csv(temp_file, index=False, encoding='utf-8-sig')
        
        if progress_file.exists():
            backup_file = Path(str(progress_file) + '.backup')
            shutil.copy2(progress_file, backup_file)
        
        shutil.move(str(temp_file), str(progress_file))
        logging.info(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        logging.error(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
        raise


def save_daily_backup(df: pd.DataFrame, output_dir: Path, today_str: str):
    """ì˜¤ëŠ˜ ì²˜ë¦¬í•œ ë°ì´í„°ë§Œ ë³„ë„ ì €ì¥"""
    try:
        today_processed = df[
            df['ì²˜ë¦¬ì¼ì‹œ'].notna() & 
            df['ì²˜ë¦¬ì¼ì‹œ'].str.startswith(today_str)
        ].copy()
        
        if len(today_processed) == 0:
            return
        
        today_file = today_str.replace('-', '')
        daily_file = output_dir / f"daily_{today_file}.csv"
        
        # ì´ë¯¸ ì˜¤ëŠ˜ ë°±ì—…ì´ ìˆìœ¼ë©´ ë³‘í•©
        if daily_file.exists():
            df_existing = pd.read_csv(daily_file, encoding='utf-8-sig')
            # ì¸ë±ìŠ¤ ê¸°ì¤€ìœ¼ë¡œ ì—…ë°ì´íŠ¸
            for idx in today_processed.index:
                if idx < len(df_existing):
                    df_existing.iloc[idx] = today_processed.iloc[0]  # ë®ì–´ì“°ê¸°
            today_processed = df_existing
        
        today_processed.to_csv(daily_file, index=False, encoding='utf-8-sig')
        
        success_count = (today_processed['ì²˜ë¦¬ìƒíƒœ'] == 'success').sum()
        logging.info(f"ğŸ“… ì¼ì¼ ë°±ì—…: {daily_file.name} ({success_count:,}ê±´ ì„±ê³µ)")
        
    except Exception as e:
        logging.error(f"âŒ ì¼ì¼ ë°±ì—… ì‹¤íŒ¨: {e}")


def main():
    API_KEY = "01C14AE8-F90A-312A-92A2-395337FDB8AF"
    INPUT_FILE = "input/charger_v2.csv"
    OUTPUT_DIR = Path("output")
    PROGRESS_FILE = OUTPUT_DIR / "progress.csv"
    DAILY_LIMIT = 40000

    OUTPUT_DIR.mkdir(exist_ok=True)
    today_str = datetime.now().strftime('%Y-%m-%d')

    logging.info("=" * 70)
    logging.info(f"ğŸš€ ì§€ì˜¤ì½”ë”© ìë™ ì‹¤í–‰")
    logging.info(f"   ğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logging.info("=" * 70)

    # ì§„í–‰ íŒŒì¼ ë¡œë“œ ë˜ëŠ” ìƒˆë¡œ ìƒì„±
    progress_df = load_progress(PROGRESS_FILE)
    if progress_df is not None:
        df = progress_df
    else:
        logging.info(f"ğŸ“‚ ì›ë³¸ íŒŒì¼ ì½ê¸°: {INPUT_FILE}")
        df = pd.read_csv(INPUT_FILE, encoding='utf-8-sig')
        df['ìœ„ë„'] = None
        df['ê²½ë„'] = None
        df['ì²˜ë¦¬ìƒíƒœ'] = 'pending'
        df['ì²˜ë¦¬ì¼ì‹œ'] = None
        logging.info(f"âœ… {len(df):,}ê±´ ë¡œë“œ (ì‹ ê·œ)")

    # ìƒí™© ë¶„ì„ ë° ì‹¤í–‰ ì—¬ë¶€ ê²°ì •
    if not analyze_situation(df, today_str):
        return

    # ì˜¤ëŠ˜ ì´ë¯¸ ì‚¬ìš©í•œ í•œë„ ê³„ì‚°
    already_used = check_today_usage(df, today_str)
    remaining_limit = DAILY_LIMIT - already_used

    logging.info(f"\nâš¡ ì‹¤í–‰ ì‹œì‘ (ë‚¨ì€ í•œë„: {remaining_limit:,}ê±´)")
    logging.info("=" * 70 + "\n")

    geocoder = VWorldGeocoder(API_KEY, remaining_limit)
    geocoder.already_used_today = already_used

    success_count = 0
    fail_count = 0
    skip_count = 0
    start_time = time.time()

    try:
        for idx in df.index:
            if df.at[idx, 'ì²˜ë¦¬ìƒíƒœ'] == 'success':
                skip_count += 1
                continue

            if geocoder.today_count >= remaining_limit:
                logging.warning("=" * 70)
                logging.warning(f"âš ï¸  ì˜¤ëŠ˜ í•œë„ ë„ë‹¬!")
                logging.warning(f"   ì˜¤ëŠ˜ ì´ ì²˜ë¦¬: {already_used + geocoder.today_count:,}ê±´")
                logging.warning("=" * 70)
                break

            road_address = df.at[idx, 'ì£¼ì†Œ'] if 'ì£¼ì†Œ' in df.columns else None
            jibun_address = df.at[idx, 'ì§€ë²ˆ ì£¼ì†Œ'] if 'ì§€ë²ˆ ì£¼ì†Œ' in df.columns else None

            lat, lon, status = geocoder.geocode_address(road_address, jibun_address)

            df.at[idx, 'ìœ„ë„'] = lat
            df.at[idx, 'ê²½ë„'] = lon
            df.at[idx, 'ì²˜ë¦¬ìƒíƒœ'] = status
            df.at[idx, 'ì²˜ë¦¬ì¼ì‹œ'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

            if status == 'success':
                success_count += 1
            elif status == 'failed':
                fail_count += 1

            if geocoder.today_count % 50 == 0:
                rate = (success_count / geocoder.today_count * 100) if geocoder.today_count > 0 else 0
                elapsed = time.time() - start_time
                speed = geocoder.today_count / elapsed if elapsed > 0 else 0
                remaining = remaining_limit - geocoder.today_count
                eta_min = int((remaining / speed / 60)) if speed > 0 else 0
                
                logging.info(f"ğŸ“Š {already_used + geocoder.today_count:>5,}ê±´ (ì˜¤ëŠ˜) | "
                             f"ì„±ê³µ: {success_count:>4,} ({rate:>4.1f}%) | "
                             f"{speed:>4.1f}ê±´/ì´ˆ | "
                             f"ë‚¨ì€ì‹œê°„: {eta_min}ë¶„")

            if geocoder.today_count % 1000 == 0:
                save_progress_safe(df, PROGRESS_FILE)

            time.sleep(0.12)

        save_progress_safe(df, PROGRESS_FILE)
        
        if geocoder.today_count > 0:
            save_daily_backup(df, OUTPUT_DIR, today_str)

    except KeyboardInterrupt:
        logging.warning("\nâš ï¸  ì¤‘ë‹¨ë¨. ì €ì¥ ì¤‘...")
        save_progress_safe(df, PROGRESS_FILE)
        if geocoder.today_count > 0:
            save_daily_backup(df, OUTPUT_DIR, today_str)
        return

    # ìµœì¢… í†µê³„
    elapsed_time = time.time() - start_time
    total_today = already_used + geocoder.today_count

    logging.info("\n" + "=" * 70)
    logging.info("ğŸ¯ ì˜¤ëŠ˜ ì‘ì—… ì™„ë£Œ")
    logging.info("=" * 70)
    logging.info(f"ì˜¤ëŠ˜ ì´ ì²˜ë¦¬:  {total_today:>10,}ê±´")
    logging.info(f"ì´ë²ˆ ì‹¤í–‰:     {geocoder.today_count:>10,}ê±´")
    logging.info(f"  âœ… ì„±ê³µ:     {success_count:>10,}ê±´")
    logging.info(f"  âŒ ì‹¤íŒ¨:     {fail_count:>10,}ê±´")
    logging.info(f"â±ï¸  ì†Œìš”ì‹œê°„:   {int(elapsed_time//60)}ë¶„ {int(elapsed_time%60)}ì´ˆ")
    
    total = len(df)
    total_success = (df['ì²˜ë¦¬ìƒíƒœ'] == 'success').sum()
    total_pending = (df['ì²˜ë¦¬ìƒíƒœ'] == 'pending').sum()
    
    logging.info("-" * 70)
    logging.info(f"ì „ì²´ ì§„í–‰ë¥ :   {total_success/total*100:>5.1f}% ({total_success:,}/{total:,}ê±´)")
    logging.info(f"ë‚¨ì€ ì‘ì—…:     {total_pending:>10,}ê±´")
    
    if total_pending > 0:
        est_days = (total_pending + 39999) // 40000
        logging.info(f"ì˜ˆìƒ ì†Œìš”:     ì•½ {est_days}ì¼")
        logging.info("\nğŸ’¡ ë‚´ì¼ ê°™ì€ ëª…ë ¹ì–´ë¡œ ì´ì–´ì„œ ì§„í–‰í•˜ì„¸ìš”!")
        logging.info("   â†’ py geocode_vworld_smart.py")
    else:
        logging.info("\nğŸ‰ ì „ì²´ ì™„ë£Œ!")
    
    logging.info("=" * 70)

if __name__ == "__main__":
    main()
