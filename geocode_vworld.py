import pandas as pd
import requests
import time
from typing import Optional, Tuple
import logging
from pathlib import Path
from datetime import datetime
import re

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('geocoding.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

class VWorldGeocoder:
    def __init__(self, api_key: str, daily_limit: int = 40000):
        self.api_key = api_key
        self.base_url = "https://api.vworld.kr/req/address"
        self.daily_limit = daily_limit
        self.today_count = 0

    def clean_address(self, address: str) -> str:
        """ì£¼ì†Œ ì •ì œ - ê³µê²©ì ìœ¼ë¡œ ë¶ˆí•„ìš”í•œ ì •ë³´ ì œê±°"""
        if pd.isna(address) or not address.strip():
            return ""
        
        addr = address.strip()

        # 1. ê´„í˜¸ ë° ê´„í˜¸ ì•ˆ ë‚´ìš© ì œê±°
        addr = re.sub(r'\([^)]*\)', '', addr)
        addr = re.sub(r'\[[^\]]*\]', '', addr)
        
        # 2. ì¶©ì „ê¸°/ì£¼ì°¨ì¥ ê´€ë ¨ í‚¤ì›Œë“œ ì™„ì „ ì œê±°
        noise_keywords = [
            'ì™„ì†ì¶©ì „ê¸°', 'ê¸‰ì†ì¶©ì „ê¸°', 'ì¶©ì „ê¸°', 'ì¶©ì „ì†Œ', 
            'ì£¼ì°¨ì¥', 'ì§€í•˜ì£¼ì°¨ì¥', 'ì˜¥ì™¸ì£¼ì°¨ì¥',
            'ì…êµ¬', 'ì•', 'ì˜†', 'ë’¤', 'ë’¤í¸', 'ë§ì€í¸', 'ê±´ë„ˆí¸',
            'ìš°ì¸¡', 'ì¢Œì¸¡', 'ë°©ë©´', 'ë°©í–¥', 'ì¸ê·¼', 'ê·¼ì²˜',
            '1ì¸µ', '2ì¸µ', 'ì§€í•˜', 'B1', 'B2', 'ì¸µ'
        ]
        for keyword in noise_keywords:
            addr = addr.replace(keyword, ' ')
        
        # 3. í–‰ì •êµ¬ì—­ëª… í‘œì¤€í™”
        addr = addr.replace('ê°•ì›íŠ¹ë³„ìì¹˜ë„', 'ê°•ì›ë„')
        addr = addr.replace('ì „ë¶íŠ¹ë³„ìì¹˜ë„', 'ì „ë¼ë¶ë„')
        addr = addr.replace('ì „ë‚¨íŠ¹ë³„ìì¹˜ë„', 'ì „ë¼ë‚¨ë„')
        addr = addr.replace('ì œì£¼íŠ¹ë³„ìì¹˜ë„', 'ì œì£¼ë„')
        
        # 4. ì˜¤íƒ€ êµì • ë° í–‰ì •êµ¬ì—­ëª… ìˆ˜ì •
        corrections = {
            # ì˜¤íƒ€ êµì •
            "í™ë•êµ¬": "í¥ë•êµ¬",
            "ì›ë¡±ë©´": "ì›”ë¡±ë©´",
            "ì›ì‚­ë¡œ": "ì›ë‹¹ë¡œ",
            "ì†¡ë°±ë¡œë¡œ": "ì†¡ë°±ë¡œ",
            
            # í–‰ì •êµ¬ì—­ ë³€ê²½ (ë©´ â†’ ì)
            "ë‹¬ì„±êµ° í˜„í’ë©´": "ë‹¬ì„±êµ° í˜„í’ì",
            "ì˜ˆì²œêµ° í˜¸ëª…ë©´": "ì˜ˆì²œêµ° í˜¸ëª…ì",
            
            # ë„ë¡œëª… ë³€í™˜ (ì‹ ì„¤ â†’ ê¸°ì¡´)
            "í˜„í’ë™ë¡œ": "í˜„í’ì¤‘ì•™ë¡œ",
            "í˜„í’ì„œë¡œ": "í˜„í’ì¤‘ì•™ë¡œ",
            "ë„ì²­ëŒ€ë¡œ": "ì¶©íš¨ë¡œ",
            "í–‰ë³µë¡œ": "ì¶©íš¨ë¡œ",
            "ì²­ì„ë¡œ": "ê²½ì¶©ëŒ€ë¡œ",
            "ìˆ˜íƒ€ì‚¬ë¡œ": "ìˆ˜íƒ€ì‚¬ê¸¸",
            "ë•í’ë¡œ": "ì‚¼ì²™ë¡œ",
        }
        for wrong, right in corrections.items():
            addr = addr.replace(wrong, right)

        # 5. ë„ì–´ì“°ê¸° ë³´ì •
        addr = re.sub(r'([ê°€-í£])(\d)', r'\1 \2', addr)
        
        # 6. ì¤‘ë³µ ê³µë°± ì œê±° ë° ì •ë¦¬
        addr = re.sub(r'\s+', ' ', addr).strip()

        return addr

    def extract_address_candidates(self, address: str) -> list:
        """ë‹¤ì–‘í•œ ë ˆë²¨ì˜ ì£¼ì†Œ í›„ë³´ë¥¼ ìƒì„± (ê³µê²©ì )"""
        candidates = []
        
        # Level 1: ì›ë³¸ ì£¼ì†Œ
        candidates.append(address)
        
        # Level 2: ê±´ë¬¼ë²ˆí˜¸ ì œê±°
        no_number = re.sub(r'\s+\d+(-\d+)?(\s|$)', ' ', address).strip()
        if no_number != address and len(no_number) > 5:
            candidates.append(no_number)
        
        # Level 3: ê¸¸/ë¡œ/ëŒ€ë¡œê¹Œì§€ë§Œ (ë„ë¡œëª…ë§Œ)
        road_match = re.match(r'(.+?[ì‹œë„êµ°êµ¬]\s+.+?[ìë©´ë™]?\s*.+?[ë¡œê¸¸ëŒ€ë¡œê°€])\s*', address)
        if road_match:
            road_only = road_match.group(1).strip()
            if road_only not in candidates and len(road_only) > 5:
                candidates.append(road_only)
        
        # Level 4: ìë©´ë™ê¹Œì§€ë§Œ
        dong_match = re.match(r'(.+?[ì‹œë„êµ°êµ¬]\s+.+?[ìë©´ë™ë¦¬])', address)
        if dong_match:
            dong_only = dong_match.group(1).strip()
            if dong_only not in candidates and len(dong_only) > 5:
                candidates.append(dong_only)
        
        # Level 5: ì‹œêµ°êµ¬ê¹Œì§€ë§Œ (ë§ˆì§€ë§‰ ìˆ˜ë‹¨)
        sigungu_match = re.match(r'(.+?[ì‹œêµ°êµ¬])', address)
        if sigungu_match:
            sigungu_only = sigungu_match.group(1).strip()
            if sigungu_only not in candidates and len(sigungu_only) > 3:
                candidates.append(sigungu_only)
        
        return candidates

    def geocode_address(self, address: str, jibun_address: str = None) -> Tuple[Optional[float], Optional[float], str]:
        """ì£¼ì†Œë¥¼ ì¢Œí‘œë¡œ ë³€í™˜ (ë‹¤ë‹¨ê³„ í´ë°±)"""
        if self.today_count >= self.daily_limit:
            return None, None, 'limit_reached'

        addresses_to_try = []
        
        # ë„ë¡œëª… ì£¼ì†Œ ì²˜ë¦¬
        if address and not pd.isna(address):
            cleaned = self.clean_address(address)
            if cleaned and len(cleaned) > 3:
                addresses_to_try.append((cleaned, 'road', 'ë„ë¡œëª…'))
        
        # ì§€ë²ˆ ì£¼ì†Œ ì²˜ë¦¬
        if jibun_address and not pd.isna(jibun_address):
            cleaned_jibun = self.clean_address(jibun_address)
            if cleaned_jibun and len(cleaned_jibun) > 3:
                addresses_to_try.append((cleaned_jibun, 'parcel', 'ì§€ë²ˆ'))

        if not addresses_to_try:
            return None, None, 'empty'

        # ê° ì£¼ì†Œ íƒ€ì…ë³„ë¡œ ë‹¤ë‹¨ê³„ ì‹œë„
        for addr, addr_type, type_name in addresses_to_try:
            candidates = self.extract_address_candidates(addr)
            
            for i, candidate in enumerate(candidates):
                if len(candidate) < 3:  # ë„ˆë¬´ ì§§ì€ ì£¼ì†ŒëŠ” ìŠ¤í‚µ
                    continue
                    
                lat, lon, status = self._try_geocode(candidate, addr_type)
                if status == 'success':
                    level_names = ['ì •í™•ì£¼ì†Œ', 'ë„ë¡œëª…', 'ë„ë¡œê¸°ì¤€', 'ìë©´ë™', 'ì‹œêµ°êµ¬']
                    level = level_names[i] if i < len(level_names) else 'ê´‘ì—­'
                    logging.info(f"âœ… ì„±ê³µ [{level}Â·{type_name}]: {candidate[:40]} â†’ ({lat:.6f}, {lon:.6f})")
                    return lat, lon, status
                
                # API í˜¸ì¶œ ê°„ ì§§ì€ ëŒ€ê¸°
                time.sleep(0.08)

        # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨
        reason = self._analyze_failure(addresses_to_try[0][0])
        short_addr = addresses_to_try[0][0][:50]
        logging.warning(f"âŒ ì‹¤íŒ¨ [{reason}]: {short_addr}")
        return None, None, 'failed'

    def _analyze_failure(self, address: str) -> str:
        """ì‹¤íŒ¨ ì›ì¸ ë¶„ì„"""
        if re.search(r'\d{4,}', address):
            return "í°ë²ˆì§€"
        elif len(address.split()) < 2:
            return "ì •ë³´ë¶€ì¡±"
        else:
            return "ë¯¸ë“±ë¡"

    def _try_geocode(self, address: str, addr_type: str = 'road') -> Tuple[Optional[float], Optional[float], str]:
        """VWorld API ìš”ì²­"""
        params = {
            'service': 'address',
            'request': 'getcoord',
            'version': '2.0',
            'crs': 'epsg:4326',
            'address': address,
            'refine': 'true',
            'simple': 'false',
            'format': 'json',
            'type': addr_type,
            'key': self.api_key
        }

        try:
            response = requests.get(self.base_url, params=params, timeout=10)
            self.today_count += 1

            if response.status_code == 200:
                data = response.json()
                res = data.get('response', {})
                status = res.get('status')
                result = res.get('result', {})

                if status == 'OK' and isinstance(result, dict) and 'point' in result:
                    lon = float(result['point']['x'])
                    lat = float(result['point']['y'])
                    return lat, lon, 'success'

            return None, None, 'failed'

        except requests.exceptions.Timeout:
            return None, None, 'failed'
        except requests.exceptions.RequestException:
            return None, None, 'failed'
        except Exception as e:
            logging.error(f"API ì˜¤ë¥˜: {str(e)}")
            return None, None, 'failed'


def load_progress(progress_file: Path) -> Optional[pd.DataFrame]:
    if progress_file.exists():
        try:
            logging.info(f"ğŸ“‚ ì´ì „ ì§„í–‰ ìƒí™© ë¡œë“œ: {progress_file}")
            return pd.read_csv(progress_file, encoding='utf-8-sig', low_memory=False)
        except Exception as e:
            logging.warning(f"ì§„í–‰ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
    return None


def save_progress(df: pd.DataFrame, progress_file: Path):
    df.to_csv(progress_file, index=False, encoding='utf-8-sig')
    logging.info(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ")


def get_batch_number(output_dir: Path) -> int:
    existing_files = list(output_dir.glob("batch_*.csv"))
    if not existing_files:
        return 1
    batch_numbers = []
    for f in existing_files:
        try:
            num = int(f.stem.split('_')[1])
            batch_numbers.append(num)
        except:
            continue
    return max(batch_numbers) + 1 if batch_numbers else 1


def print_progress_stats(df: pd.DataFrame):
    """ì§„í–‰ ìƒí™© í†µê³„ ì¶œë ¥"""
    total = len(df)
    success = (df['ì²˜ë¦¬ìƒíƒœ'] == 'success').sum()
    failed = (df['ì²˜ë¦¬ìƒíƒœ'] == 'failed').sum()
    pending = (df['ì²˜ë¦¬ìƒíƒœ'] == 'pending').sum()
    
    success_rate = (success / total * 100) if total > 0 else 0
    progress_rate = ((success + failed) / total * 100) if total > 0 else 0
    
    logging.info("=" * 70)
    logging.info("ğŸ“Š ì „ì²´ ì§„í–‰ ìƒí™©")
    logging.info("-" * 70)
    logging.info(f"ì „ì²´:      {total:>10,}ê±´ (100.0%)")
    logging.info(f"âœ… ì„±ê³µ:   {success:>10,}ê±´ ({success_rate:>5.1f}%)")
    logging.info(f"âŒ ì‹¤íŒ¨:   {failed:>10,}ê±´ ({failed/total*100:>5.1f}%)")
    logging.info(f"â³ ëŒ€ê¸°:   {pending:>10,}ê±´ ({pending/total*100:>5.1f}%)")
    logging.info("-" * 70)
    logging.info(f"ì§„í–‰ë¥ :    {progress_rate:>5.1f}%")
    
    if pending > 0:
        est_days = (pending + 39999) // 40000
        logging.info(f"ì˜ˆìƒ:      ì•½ {est_days}ì¼ (40,000ê±´/ì¼)")
    
    logging.info("=" * 70)


def main():
    API_KEY = "01C14AE8-F90A-312A-92A2-395337FDB8AF"
    INPUT_FILE = "input/charger_v2.csv"
    OUTPUT_DIR = Path("output")
    PROGRESS_FILE = OUTPUT_DIR / "progress.csv"
    DAILY_LIMIT = 40000

    OUTPUT_DIR.mkdir(exist_ok=True)
    today_str = datetime.now().strftime('%Y%m%d')

    logging.info("=" * 70)
    logging.info(f"ğŸš€ ë¸Œì´ì›”ë“œ ì§€ì˜¤ì½”ë”© ì‹œì‘")
    logging.info(f"   {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logging.info("=" * 70)

    progress_df = load_progress(PROGRESS_FILE)
    if progress_df is not None:
        df = progress_df
        logging.info(f"âœ… ì´ì „ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        print_progress_stats(df)
    else:
        logging.info(f"ğŸ“‚ íŒŒì¼ ì½ê¸°: {INPUT_FILE}")
        df = pd.read_csv(INPUT_FILE, encoding='utf-8-sig')
        df['ìœ„ë„'] = None
        df['ê²½ë„'] = None
        df['ì²˜ë¦¬ìƒíƒœ'] = 'pending'
        df['ì²˜ë¦¬ì¼ì‹œ'] = None
        logging.info(f"âœ… {len(df):,}ê±´ ë¡œë“œ (ì‹ ê·œ)")
        logging.info("=" * 70)

    batch_num = get_batch_number(OUTPUT_DIR)
    geocoder = VWorldGeocoder(API_KEY, DAILY_LIMIT)

    success_count = 0
    fail_count = 0
    skip_count = 0
    start_time = time.time()

    try:
        for idx in df.index:
            if df.at[idx, 'ì²˜ë¦¬ìƒíƒœ'] == 'success':
                skip_count += 1
                continue

            if geocoder.today_count >= DAILY_LIMIT:
                logging.warning("=" * 70)
                logging.warning(f"âš ï¸  ì¼ì¼ í•œë„ ë„ë‹¬ ({DAILY_LIMIT:,}ê±´)")
                logging.warning("=" * 70)
                save_progress(df, PROGRESS_FILE)
                break

            road_address = df.at[idx, 'ì£¼ì†Œ'] if 'ì£¼ì†Œ' in df.columns else None
            jibun_address = df.at[idx, 'ì§€ë²ˆ ì£¼ì†Œ'] if 'ì§€ë²ˆ ì£¼ì†Œ' in df.columns else None

            lat, lon, status = geocoder.geocode_address(road_address, jibun_address)

            df.at[idx, 'ìœ„ë„'] = lat
            df.at[idx, 'ê²½ë„'] = lon
            df.at[idx, 'ì²˜ë¦¬ìƒíƒœ'] = status
            df.at[idx, 'ì²˜ë¦¬ì¼ì‹œ'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

            if status == 'success':
                success_count += 1
            elif status == 'failed':
                fail_count += 1

            # 50ê±´ë§ˆë‹¤ ì§„í–‰ë¥  ì¶œë ¥
            if geocoder.today_count % 50 == 0:
                rate = (success_count / geocoder.today_count * 100) if geocoder.today_count > 0 else 0
                elapsed = time.time() - start_time
                speed = geocoder.today_count / elapsed if elapsed > 0 else 0
                remaining_requests = DAILY_LIMIT - geocoder.today_count
                eta_sec = remaining_requests / speed if speed > 0 else 0
                eta_min = int(eta_sec / 60)
                
                logging.info(f"ğŸ“Š {geocoder.today_count:>5,}ê±´ | "
                             f"ì„±ê³µ: {success_count:>4,} ({rate:>4.1f}%) | "
                             f"ì‹¤íŒ¨: {fail_count:>4,} | "
                             f"{speed:>4.1f}ê±´/ì´ˆ | "
                             f"ë‚¨ì€ì‹œê°„: {eta_min}ë¶„")

            # 1000ê±´ë§ˆë‹¤ ì¤‘ê°„ ì €ì¥
            if geocoder.today_count % 1000 == 0:
                save_progress(df, PROGRESS_FILE)

            # ì ì ˆí•œ ë”œë ˆì´
            time.sleep(0.12)

        save_progress(df, PROGRESS_FILE)

    except KeyboardInterrupt:
        logging.warning("\nâš ï¸  ì¤‘ë‹¨ë¨. ì €ì¥ ì¤‘...")
        save_progress(df, PROGRESS_FILE)
        logging.warning("âœ… ì €ì¥ ì™„ë£Œ")
        return

    # ì˜¤ëŠ˜ ì²˜ë¦¬ ê²°ê³¼ ì €ì¥
    if geocoder.today_count > 0:
        batch_output = OUTPUT_DIR / f"batch_{batch_num:02d}_{today_str}.csv"
        today_processed = df[df['ì²˜ë¦¬ì¼ì‹œ'].notna() & df['ì²˜ë¦¬ì¼ì‹œ'].str.startswith(today_str[:10])]
        if len(today_processed) > 0:
            today_processed.to_csv(batch_output, index=False, encoding='utf-8-sig')
            logging.info(f"\nğŸ’¾ ë°°ì¹˜ ì €ì¥: {batch_output.name} ({len(today_processed):,}ê±´)")

    elapsed_time = time.time() - start_time
    avg_speed = geocoder.today_count / elapsed_time if elapsed_time > 0 else 0

    logging.info("\n" + "=" * 70)
    logging.info("ğŸ¯ ì˜¤ëŠ˜ ì‘ì—… ì™„ë£Œ")
    logging.info("=" * 70)
    logging.info(f"API ìš”ì²­:  {geocoder.today_count:>10,}ê±´")
    logging.info(f"âœ… ì„±ê³µ:   {success_count:>10,}ê±´ ({success_count/geocoder.today_count*100 if geocoder.today_count > 0 else 0:>5.1f}%)")
    logging.info(f"âŒ ì‹¤íŒ¨:   {fail_count:>10,}ê±´ ({fail_count/geocoder.today_count*100 if geocoder.today_count > 0 else 0:>5.1f}%)")
    logging.info(f"â© ìŠ¤í‚µ:   {skip_count:>10,}ê±´")
    logging.info(f"â±ï¸  ì‹œê°„:   {int(elapsed_time//60)}ë¶„ {int(elapsed_time%60)}ì´ˆ")
    logging.info(f"âš¡ ì†ë„:   {avg_speed:>10.1f}ê±´/ì´ˆ")
    logging.info("-" * 70)
    
    print_progress_stats(df)

    total_pending = (df['ì²˜ë¦¬ìƒíƒœ'] == 'pending').sum()
    if total_pending > 0:
        logging.info("\nğŸ’¡ ë‚´ì¼ ì‹¤í–‰ ì‹œ ì´ì–´ì„œ ì§„í–‰ë©ë‹ˆë‹¤.")
    else:
        final_output = OUTPUT_DIR / "geocoded_final_complete.csv"
        df.to_csv(final_output, index=False, encoding='utf-8-sig')
        logging.info(f"\nğŸ‰ ì „ì²´ ì™„ë£Œ! {final_output.name}")
        
        failed_df = df[df['ì²˜ë¦¬ìƒíƒœ'] == 'failed']
        if len(failed_df) > 0:
            failed_output = OUTPUT_DIR / "geocoded_failed.csv"
            failed_df.to_csv(failed_output, index=False, encoding='utf-8-sig')
            logging.info(f"ğŸ“‹ ì‹¤íŒ¨ íŒŒì¼: {failed_output.name} ({len(failed_df):,}ê±´)")
    
    logging.info("=" * 70)

if __name__ == "__main__":
    main()
    