import pandas as pd
import requests
import time
from typing import Optional, Tuple
import logging
from pathlib import Path
from datetime import datetime
import re
import shutil

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('geocoding.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

class VWorldGeocoder:
    def __init__(self, api_key: str, daily_limit: int = 40000):
        self.api_key = api_key
        self.base_url = "https://api.vworld.kr/req/address"
        self.daily_limit = daily_limit
        self.today_count = 0

    def clean_address(self, address: str) -> str:
        """ì£¼ì†Œ ì •ì œ - ê³µê²©ì ìœ¼ë¡œ ë¶ˆí•„ìš”í•œ ì •ë³´ ì œê±°"""
        if pd.isna(address) or not address.strip():
            return ""
        
        addr = address.strip()

        # 1. ê´„í˜¸ ë° ê´„í˜¸ ì•ˆ ë‚´ìš© ì œê±°
        addr = re.sub(r'\([^)]*\)', '', addr)
        addr = re.sub(r'\[[^\]]*\]', '', addr)
        
        # 2. ì¶©ì „ê¸°/ì£¼ì°¨ì¥ ê´€ë ¨ í‚¤ì›Œë“œ ì™„ì „ ì œê±°
        noise_keywords = [
            'ì™„ì†ì¶©ì „ê¸°', 'ê¸‰ì†ì¶©ì „ê¸°', 'ì¶©ì „ê¸°', 'ì¶©ì „ì†Œ', 
            'ì£¼ì°¨ì¥', 'ì§€í•˜ì£¼ì°¨ì¥', 'ì˜¥ì™¸ì£¼ì°¨ì¥',
            'ì…êµ¬', 'ì•', 'ì˜†', 'ë’¤', 'ë’¤í¸', 'ë§ì€í¸', 'ê±´ë„ˆí¸',
            'ìš°ì¸¡', 'ì¢Œì¸¡', 'ë°©ë©´', 'ë°©í–¥', 'ì¸ê·¼', 'ê·¼ì²˜',
            '1ì¸µ', '2ì¸µ', 'ì§€í•˜', 'B1', 'B2', 'ì¸µ'
        ]
        for keyword in noise_keywords:
            addr = addr.replace(keyword, ' ')
        
        # 3. í–‰ì •êµ¬ì—­ëª… í‘œì¤€í™”
        addr = addr.replace('ê°•ì›íŠ¹ë³„ìì¹˜ë„', 'ê°•ì›ë„')
        addr = addr.replace('ì „ë¶íŠ¹ë³„ìì¹˜ë„', 'ì „ë¼ë¶ë„')
        addr = addr.replace('ì „ë‚¨íŠ¹ë³„ìì¹˜ë„', 'ì „ë¼ë‚¨ë„')
        addr = addr.replace('ì œì£¼íŠ¹ë³„ìì¹˜ë„', 'ì œì£¼ë„')
        
        # 4. ì˜¤íƒ€ êµì • ë° í–‰ì •êµ¬ì—­ëª… ìˆ˜ì •
        corrections = {
            "í™ë•êµ¬": "í¥ë•êµ¬",
            "ì›ë¡±ë©´": "ì›”ë¡±ë©´",
            "ì›ì‚­ë¡œ": "ì›ë‹¹ë¡œ",
            "ì†¡ë°±ë¡œë¡œ": "ì†¡ë°±ë¡œ",
            "ë‹¬ì„±êµ° í˜„í’ë©´": "ë‹¬ì„±êµ° í˜„í’ì",
            "ì˜ˆì²œêµ° í˜¸ëª…ë©´": "ì˜ˆì²œêµ° í˜¸ëª…ì",
            "í˜„í’ë™ë¡œ": "í˜„í’ì¤‘ì•™ë¡œ",
            "í˜„í’ì„œë¡œ": "í˜„í’ì¤‘ì•™ë¡œ",
            "ë„ì²­ëŒ€ë¡œ": "ì¶©íš¨ë¡œ",
            "í–‰ë³µë¡œ": "ì¶©íš¨ë¡œ",
            "ì²­ì„ë¡œ": "ê²½ì¶©ëŒ€ë¡œ",
            "ìˆ˜íƒ€ì‚¬ë¡œ": "ìˆ˜íƒ€ì‚¬ê¸¸",
            "ë•í’ë¡œ": "ì‚¼ì²™ë¡œ",
        }
        for wrong, right in corrections.items():
            addr = addr.replace(wrong, right)

        # 5. ë„ì–´ì“°ê¸° ë³´ì •
        addr = re.sub(r'([ê°€-í£])(\d)', r'\1 \2', addr)
        
        # 6. ì¤‘ë³µ ê³µë°± ì œê±° ë° ì •ë¦¬
        addr = re.sub(r'\s+', ' ', addr).strip()

        return addr

    def extract_address_candidates(self, address: str) -> list:
        """ë‹¤ì–‘í•œ ë ˆë²¨ì˜ ì£¼ì†Œ í›„ë³´ë¥¼ ìƒì„±"""
        candidates = []
        candidates.append(address)
        
        no_number = re.sub(r'\s+\d+(-\d+)?(\s|$)', ' ', address).strip()
        if no_number != address and len(no_number) > 5:
            candidates.append(no_number)
        
        road_match = re.match(r'(.+?[ì‹œë„êµ°êµ¬]\s+.+?[ìë©´ë™]?\s*.+?[ë¡œê¸¸ëŒ€ë¡œê°€])\s*', address)
        if road_match:
            road_only = road_match.group(1).strip()
            if road_only not in candidates and len(road_only) > 5:
                candidates.append(road_only)
        
        dong_match = re.match(r'(.+?[ì‹œë„êµ°êµ¬]\s+.+?[ìë©´ë™ë¦¬])', address)
        if dong_match:
            dong_only = dong_match.group(1).strip()
            if dong_only not in candidates and len(dong_only) > 5:
                candidates.append(dong_only)
        
        return candidates

    def geocode_address(self, address: str, jibun_address: str = None) -> Tuple[Optional[float], Optional[float], str]:
        """ì£¼ì†Œë¥¼ ì¢Œí‘œë¡œ ë³€í™˜"""
        if self.today_count >= self.daily_limit:
            return None, None, 'limit_reached'

        addresses_to_try = []
        
        if address and not pd.isna(address):
            cleaned = self.clean_address(address)
            if cleaned and len(cleaned) > 3:
                addresses_to_try.append((cleaned, 'road', 'ë„ë¡œëª…'))
        
        if jibun_address and not pd.isna(jibun_address):
            cleaned_jibun = self.clean_address(jibun_address)
            if cleaned_jibun and len(cleaned_jibun) > 3:
                addresses_to_try.append((cleaned_jibun, 'parcel', 'ì§€ë²ˆ'))

        if not addresses_to_try:
            return None, None, 'empty'

        for addr, addr_type, type_name in addresses_to_try:
            candidates = self.extract_address_candidates(addr)
            
            for i, candidate in enumerate(candidates):
                if len(candidate) < 3:
                    continue
                lat, lon, status = self._try_geocode(candidate, addr_type)
                if status == 'success':
                    level_names = ['ì •í™•ì£¼ì†Œ', 'ë„ë¡œëª…', 'ë„ë¡œê¸°ì¤€', 'ìë©´ë™']
                    level = level_names[i] if i < len(level_names) else 'ê´‘ì—­'
                    logging.info(f"âœ… ì„±ê³µ [{level}Â·{type_name}]: {candidate[:40]} â†’ ({lat:.6f}, {lon:.6f})")
                    return lat, lon, status
                time.sleep(0.08)

        return None, None, 'failed'

    def _try_geocode(self, address: str, addr_type: str = 'road') -> Tuple[Optional[float], Optional[float], str]:
        """VWorld API ìš”ì²­"""
        params = {
            'service': 'address',
            'request': 'getcoord',
            'version': '2.0',
            'crs': 'epsg:4326',
            'address': address,
            'refine': 'true',
            'simple': 'false',
            'format': 'json',
            'type': addr_type,
            'key': self.api_key
        }

        try:
            response = requests.get(self.base_url, params=params, timeout=10)
            self.today_count += 1

            if response.status_code == 200:
                data = response.json()
                res = data.get('response', {})
                status = res.get('status')
                result = res.get('result', {})

                if status == 'OK' and isinstance(result, dict) and 'point' in result:
                    lon = float(result['point']['x'])
                    lat = float(result['point']['y'])
                    return lat, lon, 'success'

            return None, None, 'failed'

        except:
            return None, None, 'failed'


def load_progress(progress_file: Path) -> Optional[pd.DataFrame]:
    """ì§„í–‰ íŒŒì¼ ë¡œë“œ"""
    if progress_file.exists():
        try:
            logging.info(f"ğŸ“‚ ì´ì „ ì§„í–‰ ìƒí™© ë¡œë“œ: {progress_file}")
            return pd.read_csv(progress_file, encoding='utf-8-sig', low_memory=False)
        except Exception as e:
            logging.warning(f"âš ï¸ ì§„í–‰ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
    return None


def save_progress_safe(df: pd.DataFrame, progress_file: Path):
    """ì•ˆì „í•œ ì €ì¥ (ì›ìì  ì €ì¥)"""
    try:
        # ì„ì‹œ íŒŒì¼ì— ë¨¼ì € ì €ì¥
        temp_file = Path(str(progress_file) + '.tmp')
        df.to_csv(temp_file, index=False, encoding='utf-8-sig')
        
        # ê¸°ì¡´ íŒŒì¼ ë°±ì—…
        if progress_file.exists():
            backup_file = Path(str(progress_file) + '.backup')
            shutil.copy2(progress_file, backup_file)
        
        # ì„ì‹œ íŒŒì¼ì„ ì‹¤ì œ íŒŒì¼ë¡œ ì´ë™
        shutil.move(str(temp_file), str(progress_file))
        
        logging.info(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ")
        
    except Exception as e:
        logging.error(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
        raise


def save_daily_backup(df: pd.DataFrame, output_dir: Path, today_str: str):
    """ì˜¤ëŠ˜ ì²˜ë¦¬í•œ ë°ì´í„°ë§Œ ë³„ë„ ì €ì¥ (ë‚ ì§œë³„ ë°±ì—…)"""
    try:
        # ì˜¤ëŠ˜ ì²˜ë¦¬ëœ ë°ì´í„°ë§Œ í•„í„°ë§
        today_processed = df[
            df['ì²˜ë¦¬ì¼ì‹œ'].notna() & 
            df['ì²˜ë¦¬ì¼ì‹œ'].str.startswith(today_str)
        ].copy()
        
        if len(today_processed) == 0:
            logging.warning("âš ï¸ ì˜¤ëŠ˜ ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ë‚ ì§œë³„ íŒŒì¼ëª… ìƒì„± (ì˜ˆ: daily_20251023.csv)
        today_file = today_str.replace('-', '')
        daily_file = output_dir / f"daily_{today_file}.csv"
        
        # ì €ì¥
        today_processed.to_csv(daily_file, index=False, encoding='utf-8-sig')
        
        success_count = (today_processed['ì²˜ë¦¬ìƒíƒœ'] == 'success').sum()
        logging.info(f"ğŸ“… ì˜¤ëŠ˜ ë°±ì—… ì €ì¥: {daily_file.name}")
        logging.info(f"   ì´ {len(today_processed):,}ê±´ (ì„±ê³µ: {success_count:,}ê±´)")
        
    except Exception as e:
        logging.error(f"âŒ ì¼ì¼ ë°±ì—… ì €ì¥ ì‹¤íŒ¨: {e}")


def print_progress_stats(df: pd.DataFrame):
    """ì§„í–‰ ìƒí™© í†µê³„ ì¶œë ¥"""
    total = len(df)
    success = (df['ì²˜ë¦¬ìƒíƒœ'] == 'success').sum()
    failed = (df['ì²˜ë¦¬ìƒíƒœ'] == 'failed').sum()
    pending = (df['ì²˜ë¦¬ìƒíƒœ'] == 'pending').sum()
    
    success_rate = (success / total * 100) if total > 0 else 0
    progress_rate = ((success + failed) / total * 100) if total > 0 else 0
    
    logging.info("=" * 70)
    logging.info("ğŸ“Š ì „ì²´ ì§„í–‰ ìƒí™©")
    logging.info("-" * 70)
    logging.info(f"ì „ì²´:      {total:>10,}ê±´ (100.0%)")
    logging.info(f"âœ… ì„±ê³µ:   {success:>10,}ê±´ ({success_rate:>5.1f}%)")
    logging.info(f"âŒ ì‹¤íŒ¨:   {failed:>10,}ê±´ ({failed/total*100:>5.1f}%)")
    logging.info(f"â³ ëŒ€ê¸°:   {pending:>10,}ê±´ ({pending/total*100:>5.1f}%)")
    logging.info("-" * 70)
    logging.info(f"ì§„í–‰ë¥ :    {progress_rate:>5.1f}%")
    
    if pending > 0:
        est_days = (pending + 39999) // 40000
        logging.info(f"ì˜ˆìƒ:      ì•½ {est_days}ì¼ (40,000ê±´/ì¼)")
    
    logging.info("=" * 70)


def main():
    API_KEY = "01C14AE8-F90A-312A-92A2-395337FDB8AF"
    INPUT_FILE = "input/charger_v2.csv"
    OUTPUT_DIR = Path("output")
    PROGRESS_FILE = OUTPUT_DIR / "progress.csv"
    DAILY_LIMIT = 40000

    OUTPUT_DIR.mkdir(exist_ok=True)

    today_str = datetime.now().strftime('%Y-%m-%d')

    logging.info("=" * 70)
    logging.info(f"ğŸš€ ë¸Œì´ì›”ë“œ ì§€ì˜¤ì½”ë”© (ì•ˆì „ ëª¨ë“œ + ì¼ì¼ ë°±ì—…)")
    logging.info(f"   {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logging.info("=" * 70)

    # ì§„í–‰ íŒŒì¼ ë¡œë“œ ë˜ëŠ” ìƒˆë¡œ ìƒì„±
    progress_df = load_progress(PROGRESS_FILE)
    if progress_df is not None:
        df = progress_df
        logging.info(f"âœ… ì´ì „ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        print_progress_stats(df)
    else:
        logging.info(f"ğŸ“‚ ì›ë³¸ íŒŒì¼ ì½ê¸°: {INPUT_FILE}")
        df = pd.read_csv(INPUT_FILE, encoding='utf-8-sig')
        df['ìœ„ë„'] = None
        df['ê²½ë„'] = None
        df['ì²˜ë¦¬ìƒíƒœ'] = 'pending'
        df['ì²˜ë¦¬ì¼ì‹œ'] = None
        logging.info(f"âœ… {len(df):,}ê±´ ë¡œë“œ (ì‹ ê·œ)")
        logging.info("=" * 70)

    geocoder = VWorldGeocoder(API_KEY, DAILY_LIMIT)

    success_count = 0
    fail_count = 0
    skip_count = 0
    start_time = time.time()

    try:
        for idx in df.index:
            # ì´ë¯¸ ì„±ê³µí•œ ê±´ì€ ìŠ¤í‚µ
            if df.at[idx, 'ì²˜ë¦¬ìƒíƒœ'] == 'success':
                skip_count += 1
                continue

            # ì¼ì¼ í•œë„ ì²´í¬
            if geocoder.today_count >= DAILY_LIMIT:
                logging.warning("=" * 70)
                logging.warning(f"âš ï¸  ì¼ì¼ í•œë„ ë„ë‹¬ ({DAILY_LIMIT:,}ê±´)")
                logging.warning("=" * 70)
                break

            road_address = df.at[idx, 'ì£¼ì†Œ'] if 'ì£¼ì†Œ' in df.columns else None
            jibun_address = df.at[idx, 'ì§€ë²ˆ ì£¼ì†Œ'] if 'ì§€ë²ˆ ì£¼ì†Œ' in df.columns else None

            lat, lon, status = geocoder.geocode_address(road_address, jibun_address)

            df.at[idx, 'ìœ„ë„'] = lat
            df.at[idx, 'ê²½ë„'] = lon
            df.at[idx, 'ì²˜ë¦¬ìƒíƒœ'] = status
            df.at[idx, 'ì²˜ë¦¬ì¼ì‹œ'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

            if status == 'success':
                success_count += 1
            elif status == 'failed':
                fail_count += 1

            # 50ê±´ë§ˆë‹¤ ì§„í–‰ë¥  ì¶œë ¥
            if geocoder.today_count % 50 == 0:
                rate = (success_count / geocoder.today_count * 100) if geocoder.today_count > 0 else 0
                elapsed = time.time() - start_time
                speed = geocoder.today_count / elapsed if elapsed > 0 else 0
                remaining = DAILY_LIMIT - geocoder.today_count
                eta_min = int((remaining / speed / 60)) if speed > 0 else 0
                
                logging.info(f"ğŸ“Š {geocoder.today_count:>5,}ê±´ | "
                             f"ì„±ê³µ: {success_count:>4,} ({rate:>4.1f}%) | "
                             f"ì‹¤íŒ¨: {fail_count:>4,} | "
                             f"{speed:>4.1f}ê±´/ì´ˆ | "
                             f"ë‚¨ì€ì‹œê°„: {eta_min}ë¶„")

            # 1000ê±´ë§ˆë‹¤ ì¤‘ê°„ ì €ì¥
            if geocoder.today_count % 1000 == 0:
                save_progress_safe(df, PROGRESS_FILE)

            time.sleep(0.12)

        # ìµœì¢… ì €ì¥
        save_progress_safe(df, PROGRESS_FILE)
        
        # ì˜¤ëŠ˜ ì²˜ë¦¬í•œ ë°ì´í„°ë¥¼ ë‚ ì§œë³„ ë°±ì—…ìœ¼ë¡œ ì €ì¥
        if geocoder.today_count > 0:
            save_daily_backup(df, OUTPUT_DIR, today_str)

    except KeyboardInterrupt:
        logging.warning("\nâš ï¸  ì¤‘ë‹¨ë¨. ì €ì¥ ì¤‘...")
        save_progress_safe(df, PROGRESS_FILE)
        if geocoder.today_count > 0:
            save_daily_backup(df, OUTPUT_DIR, today_str)
        logging.warning("âœ… ì €ì¥ ì™„ë£Œ")
        return
    except Exception as e:
        logging.error(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        save_progress_safe(df, PROGRESS_FILE)
        if geocoder.today_count > 0:
            save_daily_backup(df, OUTPUT_DIR, today_str)
        raise

    # í†µê³„ ì¶œë ¥
    elapsed_time = time.time() - start_time
    avg_speed = geocoder.today_count / elapsed_time if elapsed_time > 0 else 0

    logging.info("\n" + "=" * 70)
    logging.info("ğŸ¯ ì˜¤ëŠ˜ ì‘ì—… ì™„ë£Œ")
    logging.info("=" * 70)
    logging.info(f"API ìš”ì²­:  {geocoder.today_count:>10,}ê±´")
    logging.info(f"âœ… ì„±ê³µ:   {success_count:>10,}ê±´ ({success_count/geocoder.today_count*100 if geocoder.today_count > 0 else 0:>5.1f}%)")
    logging.info(f"âŒ ì‹¤íŒ¨:   {fail_count:>10,}ê±´ ({fail_count/geocoder.today_count*100 if geocoder.today_count > 0 else 0:>5.1f}%)")
    logging.info(f"â© ìŠ¤í‚µ:   {skip_count:>10,}ê±´")
    logging.info(f"â±ï¸  ì‹œê°„:   {int(elapsed_time//60)}ë¶„ {int(elapsed_time%60)}ì´ˆ")
    logging.info(f"âš¡ ì†ë„:   {avg_speed:>10.1f}ê±´/ì´ˆ")
    logging.info("-" * 70)
    
    print_progress_stats(df)

    total_pending = (df['ì²˜ë¦¬ìƒíƒœ'] == 'pending').sum()
    if total_pending > 0:
        logging.info("\nğŸ’¡ ë‚´ì¼ ì‹¤í–‰ ì‹œ ì´ì–´ì„œ ì§„í–‰ë©ë‹ˆë‹¤.")
    else:
        final_output = OUTPUT_DIR / "geocoded_final_complete.csv"
        df.to_csv(final_output, index=False, encoding='utf-8-sig')
        logging.info(f"\nğŸ‰ ì „ì²´ ì™„ë£Œ! {final_output.name}")
        
        failed_df = df[df['ì²˜ë¦¬ìƒíƒœ'] == 'failed']
        if len(failed_df) > 0:
            failed_output = OUTPUT_DIR / "geocoded_failed.csv"
            failed_df.to_csv(failed_output, index=False, encoding='utf-8-sig')
            logging.info(f"ğŸ“‹ ì‹¤íŒ¨ íŒŒì¼: {failed_output.name} ({len(failed_df):,}ê±´)")
    
    logging.info("=" * 70)

if __name__ == "__main__":
    main()
    